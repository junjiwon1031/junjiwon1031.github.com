---
title: Pelee 리뷰
author: Jiwon Jun
date: 2019-02-19 20:00
layout: post
---

Pelee - A Real-Time Object Detection System on Mobile Devices 리뷰
================
[*논문 바로보기*](https://arxiv.org/pdf/1804.06882.pdf)

## 가벼워도 성능 좋고 스피드도 빠르다! 3마리 토끼를 잡은 detector
SSD 가 나오고도 벌써 3년, 수많은 Convolutional Neural Network 기반의 detector 들이 등장하였다. 

FPN, RetinaNet, YoloV3 등 성능적인 부분을 개선한 논문도 있고 속도적인 부분을 개선한 논문도 많다.

모두 훌륭한 논문이지만, 오늘 볼 것은 다른 쪽으로 노력한 친구들이다.

SSD로 돌아가서, 해당 모델이 빠른 것인 사실이지만, 그것은 언제나 *연구환경* 에서다. 

59FPS의 놀라운 성능은 **TITAN X**, **Intel Xeon E5-2667v3@3.20GHz**에서 발생한다. 

SSD를 연구실 환경에서 열심히 돌려봤는데 정말 아무리 잘 나와야 45FPS 정도였다.

만약 이 모델을 그대로 핸드폰에서 돌린다면 답답한 속도와 함께 핸드폰은 따뜻한 손난로로 변할 것이다.


이러한 제한된 메모리와 연산력에서 빠르고 정확한 detector 가 오늘 볼 논문 Pelee의 목표이다.

이 분야의 대표주자로 [MobileNet](https://arxiv.org/pdf/1704.04861.pdf "MobileNet"), [MobileNetV2](https://arxiv.org/pdf/1801.04381.pdf "MobileNetv2"), [ShuffleNet](https://arxiv.org/pdf/1707.01083.pdf "ShuffleNet") 가 있다. 

각각이 가지고 있는 특징들은 조금씩 다르지만, 한 가지 공통점으로 Depthwise Seperable Convolution(Dw convolution) 을 사용한다. 이 분야의 선구자인 MobileNet 을 시작으로 연산량 줄이기위해 정석적으로 사용되는 방식이었다.

>![ssd 결과](/assets/depthwise_seperable_convolution.PNG)
>
> 기존은 3 x 3 x M x N filter 를 썼다면 dw convolution 에서는 3 x 3 x 1 x M 과 1 x 1 x M x N 을 쓰는 것이다. 
>
> 성능은 비슷하지만 연산량은 크게 준다! ((3 x 3 x M x N) x w x h vs (3 x 3 x M + M x N) x w x h)

Pelee 는 이에 당돌하게 맞서며 Conventional Convolution 으로 충분하다고 나온 논문이다.

Abstract 와 Introduction 에 계속 *현재 딥러닝 프레임워크로 효율적으로 구현하기 어렵다* 를 강조하는 것을 보면 아마 위 논문들을 구현하다가 그 복잡함에 단단히 화가 난 것 같다. 

차근차근 그들의 논문을 살펴보며 Conventional Convolution만으로 어떻게 극복하였는지 살펴보자.

-------

## Depthwise Seperable Convolution 게섯거라, 토종 Convolution 나가신다!

CNN을 제한된 메모리와 계산량으로 좋은 성능을 내려던 시도는 전에도 많이 있었으며, 아까도 말한 MobileNet 과 ShuffleNet 이 그 선두주자라 할 수 있겠다.

다만 이 두 개의 경우 dw convolution 에 크게 의존하고 있다는 문제점을 말하며 구현의 효율도 떨어진다며 다른 방식을 제시한다.

### Mobile Device 를 위한 [DenseNet](https://arxiv.org/pdf/1608.06993.pdf "DenseNet") 기반의 PeleeNet
  PeleeNet 은 DenseNet-41을 변형시켜 만든 네트워크로 MobileNet 에 비해서 66% 밖에 안 되는 모델 크기를 가지면서 성능도 1.5% 높고 속도도 아주 빠르다고 한다. (NVIDIA TX2에서 **1초에 240장**의 이미지 분류!) 
  
  그렇다면 어떤 방식을 이용해 dw convolution 없이도 좋은 성능을 보일 수 있었을까?
     
- 원래의 Dense layer 대신 Two-way Dense layer 를 사용한다.
  
  원래 DenseNet 에 사용되는 Dense layer 에는 1 x 1 과 3 x 3, 두 개의 convolution 결과를 원본과 concatenate 하여 사용된다. 
  
  여기에 3 x 3 convolution 을 두 번 시행한 결과를 같이 이용한다면? dense layer 를 두개 쌓은 것과 비슷한 receptive field 를 한 layer 로 얻을 수 있을 것이다.
  
  자세히 알고 싶다면 이 방식을 가장 먼저 사용했던 [GoogLeNet](https://www.cs.unc.edu/~wliu/papers/GoogLeNet.pdf "GoogLeNet") 을 참조해보자 
  
- Stem Block 을 Dense Block 전에 둔다.
- BottleNeck Layer 의 채널 수를 유동적으로 한다.
- Transition Layer 의 Compression 을 사용하지 않는다.
- Composite Function 을 사용한다.

